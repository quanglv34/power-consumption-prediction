{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv', index_col=0)\n",
    "test = pd.read_csv('../data/test.csv', index_col=0)\n",
    "weather = pd.read_csv('../data/weather.csv', index_col=0)\n",
    "meta = pd.read_csv('../data/metadata.csv')\n",
    "holidays = pd.read_csv('../data/holidays.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling Energy Consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_value(data):\n",
    "    forecast_ids =  data[\"ForecastId\"].unique()\n",
    "    resampled_values = pd.DataFrame()\n",
    "    for forecast_id in forecast_ids:\n",
    "        print(\"Resampling ForecastId: \", forecast_id)\n",
    "        forecast_values = data[data[\"ForecastId\"] == forecast_id].copy()\n",
    "        forecast_values['Timestamp'] = pd.to_datetime(forecast_values['Timestamp'])\n",
    "        forecast_values = forecast_values.reset_index().set_index('Timestamp')\n",
    "        forecast_values.resample('D').sum()\n",
    "\n",
    "        if resampled_values.empty:\n",
    "            resampled_values = forecast_values\n",
    "        else:\n",
    "            resampled_values = pd.concat([resampled_values, forecast_values])\n",
    "    return resampled_values\n",
    "\n",
    "resampled_train = resample_value(train)\n",
    "resampled_test = resample_value(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_train.to_csv('../data/resampled/resampled_train.csv', index = True)\n",
    "resampled_test.to_csv('../data/resampled/resampled_test.csv', index = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_weather = weather.sort_values(['Timestamp', 'SiteId', 'Distance']).copy()\n",
    "resampled_weather = resampled_weather.reset_index().drop_duplicates(['Timestamp', 'SiteId'], keep=\"first\")\n",
    "resampled_weather = weather.reset_index(level=0)\n",
    "resampled_weather['Timestamp'] = pd.to_datetime(resampled_weather['Timestamp'])\n",
    "resampled_weather = resampled_weather.reset_index().set_index('Timestamp')\n",
    "resampled_weather.drop(['index', 'Temperature'], axis=1)\n",
    "resampled_weather.resample('D').agg({'Temperature': np.median})\n",
    "resampled_weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_weather.to_csv('../data/resampled/resampled_weather.csv', index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_train = pd.read_csv('../data/resampled/resampled_train.csv', index_col=None)\n",
    "resampled_test = pd.read_csv('../data/resampled/resampled_test.csv', index_col=None)\n",
    "resampled_weather = pd.read_csv('../data/resampled/resampled_weather.csv', index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>obs_id</th>\n",
       "      <th>SiteId</th>\n",
       "      <th>ForecastId</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-08-29 00:00:00</td>\n",
       "      <td>1677832</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.413780e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-08-30 00:00:00</td>\n",
       "      <td>5379616</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.927612e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-08-31 00:00:00</td>\n",
       "      <td>496261</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.288439e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-09-01 00:00:00</td>\n",
       "      <td>4567147</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.399679e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-09-02 00:00:00</td>\n",
       "      <td>3684873</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.576456e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Timestamp   obs_id  SiteId  ForecastId         Value\n",
       "0  2015-08-29 00:00:00  1677832       1           1  7.413780e+06\n",
       "1  2015-08-30 00:00:00  5379616       1           1  8.927612e+06\n",
       "2  2015-08-31 00:00:00   496261       1           1  7.288439e+06\n",
       "3  2015-09-01 00:00:00  4567147       1           1  8.399679e+06\n",
       "4  2015-09-02 00:00:00  3684873       1           1  7.576456e+06"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resampled_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_time(df):\n",
    "    \n",
    "    df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "    df = df.set_index('Timestamp')\n",
    "    \n",
    "    df['wday'] = df.index.dayofweek\n",
    "    df['mday'] = df.index.day\n",
    "    df['yday'] = df.index.dayofyear\n",
    "    df['month'] = df.index.month\n",
    "    df['year'] = df.index.year\n",
    "    \n",
    "    df = df.reset_index(level=0)\n",
    "    \n",
    "    return df\n",
    "\n",
    "processed_train = process_time(resampled_train)\n",
    "processed_test = process_time(resampled_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>obs_id</th>\n",
       "      <th>SiteId</th>\n",
       "      <th>ForecastId</th>\n",
       "      <th>Value</th>\n",
       "      <th>wday</th>\n",
       "      <th>mday</th>\n",
       "      <th>yday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-09-03</td>\n",
       "      <td>744519</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.096555e+05</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>246</td>\n",
       "      <td>9</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-09-04</td>\n",
       "      <td>7627564</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.748273e+06</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>247</td>\n",
       "      <td>9</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-09-05</td>\n",
       "      <td>7034705</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>248</td>\n",
       "      <td>9</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-09-06</td>\n",
       "      <td>5995486</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>249</td>\n",
       "      <td>9</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-09-07</td>\n",
       "      <td>7326510</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>250</td>\n",
       "      <td>9</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Timestamp   obs_id  SiteId  ForecastId         Value  wday  mday  yday  \\\n",
       "0 2014-09-03   744519       1           1  9.096555e+05     2     3   246   \n",
       "1 2014-09-04  7627564       1           1  1.748273e+06     3     4   247   \n",
       "2 2014-09-05  7034705       1           1           NaN     4     5   248   \n",
       "3 2014-09-06  5995486       1           1           NaN     5     6   249   \n",
       "4 2014-09-07  7326510       1           1           NaN     6     7   250   \n",
       "\n",
       "   month  year  \n",
       "0      9  2014  \n",
       "1      9  2014  \n",
       "2      9  2014  \n",
       "3      9  2014  \n",
       "4      9  2014  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resampled_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_weather(df: pd.DataFrame, weather: pd.DataFrame):\n",
    "    \n",
    "    original_length = len(df)\n",
    "    \n",
    "    df = pd.merge(df, weather, how = 'left', on = ['Timestamp', 'SiteId'])\n",
    "    \n",
    "    df = df.drop_duplicates(['Timestamp', 'SiteId'], keep='first')\n",
    "    \n",
    "    new_length = len(df)\n",
    "    \n",
    "    assert original_length == new_length, 'New Length must match original length'\n",
    "\n",
    "    return df\n",
    "\n",
    "processed_train = add_weather(processed_train, resampled_weather)\n",
    "processed_test = add_weather(processed_test, resampled_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_ids = set(meta['SiteId'])\n",
    "all_meta = pd.DataFrame(columns=['SiteId', 'wday', 'off'])\n",
    "\n",
    "for site in site_ids:\n",
    "    # Extract the metadata information for the site\n",
    "    meta_slice = meta.loc[meta['SiteId'] == site]\n",
    "    \n",
    "    # Create a new dataframe for the site\n",
    "    site_meta = pd.DataFrame(\n",
    "        columns=['SiteId', 'wday', 'off', 'BaseTemperature', 'Surface'],\n",
    "        index = [0, 1, 2, 3, 4, 5, 6]\n",
    "    )\n",
    "    \n",
    "    site_meta['wday'] = [0, 1, 2, 3, 4, 5, 6]\n",
    "    site_meta['SiteId'] = site\n",
    "\n",
    "    # Record the days off\n",
    "    site_meta.loc[0, 'off'] = float(meta_slice['MondayIsDayOff'])\n",
    "    site_meta.loc[1, 'off'] = float(meta_slice['TuesdayIsDayOff'])\n",
    "    site_meta.loc[2, 'off'] = float(meta_slice['WednesdayIsDayOff'])\n",
    "    site_meta.loc[3, 'off'] = float(meta_slice['ThursdayIsDayOff'])\n",
    "    site_meta.loc[4, 'off'] = float(meta_slice['FridayIsDayOff'])\n",
    "    site_meta.loc[5, 'off'] = float(meta_slice['SaturdayIsDayOff'])\n",
    "    site_meta.loc[6, 'off'] = float(meta_slice['SundayIsDayOff'])\n",
    "\n",
    "    site_meta['BaseTemperature'] = float(meta_slice['BaseTemperature'])\n",
    "    site_meta['Surface'] = float(meta_slice['Surface'])\n",
    "    \n",
    "    # Append the resulting dataframe to all site dataframe\n",
    "    all_meta = pd.concat([all_meta, site_meta])\n",
    "\n",
    "# Find the days off in the training and testing data\n",
    "resampled_train = train.merge(all_meta, how = 'left', on = ['SiteId', 'wday'])\n",
    "test = test.merge(all_meta, how = 'left', on = ['SiteId', 'wday'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train.head()\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_weather(df: pd.DataFrame, weather: pd.DataFrame):\n",
    "    \n",
    "    original_length = len(df)\n",
    "    \n",
    "    df = pd.merge(df, weather, how = 'left', on = ['Timestamp', 'SiteId'])\n",
    "    \n",
    "    df = df.sort_values(['Timestamp', 'SiteId', 'Distance'])\n",
    "    df = df.drop_duplicates(['Timestamp', 'SiteId'], keep='first')\n",
    "    \n",
    "    new_length = len(df)\n",
    "    \n",
    "    assert original_length == new_length, 'New Length must match original length'\n",
    "\n",
    "    return df\n",
    "\n",
    "train = add_weather(train, weather)\n",
    "test = add_weather(test, weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# site = 2\n",
    "# train_df = train[train['SiteId'] == site].sort_values(['Timestamp', 'Distance'])\n",
    "# test_df = test[test['SiteId'] == site].sort_values(['Timestamp', 'Distance'])\n",
    "# # train_df['Timestamp'].max()\n",
    "# # test_df['Timestamp'].min()\n",
    "# train_df = train_df[train_df['Timestamp'] < test_df['Timestamp'].min()]\n",
    "# site_values = train_df.groupby(['year', 'month', 'mday'])['Value'].sum()\n",
    "# site_values.reset_index()\n",
    "# train_df = train_df.drop_duplicates(['year', 'month', 'mday']).merge(site_values, how = 'left', on = ['year', 'month', 'mday'])\n",
    "\n",
    "# train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(forecast_id):\n",
    "\tprint(\"Current forecast_id \", forecast_id)\n",
    "\t# Drop duplicate in testing data\n",
    "\ttest_df = test[test['ForecastId'] == forecast_id].sort_values(['Timestamp', 'Distance'])\n",
    "\ttest_df = test_df.drop_duplicates(['Timestamp'], keep='first')\n",
    "\n",
    "\t# Drop duplicate in training data\n",
    "\ttrain_df = train[train['ForecastId'] == forecast_id].sort_values(['Timestamp', 'Distance'])\n",
    "\ttrain_df = train_df.drop_duplicates(['Timestamp'], keep='first')\n",
    "\n",
    "\t# Filter to only use past training data\n",
    "\ttrain_df = train_df[train_df['Timestamp'] < test_df['Timestamp'].min()]\n",
    "\n",
    "\tprint(train.head())\n",
    "\t\n",
    "\tif(len(train_df) <= 0): \n",
    "\t\treturn pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "\t# Impute the missing values\n",
    "\tvalue_median_imputer = SimpleImputer(missing_values=np.NaN, strategy='median')\n",
    "\tvalue_median_imputer.fit(train_df[['Value']])\n",
    "\n",
    "\tif pd.isnull(train_df['Value']).all():\n",
    "\t\ttrain_df['Value'] = 0\n",
    "\telse:\n",
    "\t\ttrain_df['Value'] = value_median_imputer.transform(train_df[['Value']])\n",
    "\n",
    "\t# If all training temperatures are missing, drop temperatures from both training and testing\n",
    "\tif (np.all(np.isnan(train_df['Temperature']))) or (np.all(np.isnan(test_df['Temperature']))):\n",
    "\t\ttrain_df = train_df.drop(labels = 'Temperature', axis=1)\n",
    "\t\ttest_df = test_df.drop(labels= 'Temperature', axis=1)\n",
    "\n",
    "\t# Otherwise impute the missing temperatures\n",
    "\telse:\n",
    "\t\ttemp_median_imputer = SimpleImputer(missing_values=np.NaN, strategy='median')\n",
    "\t\ttemp_median_imputer.fit(train_df[['Temperature']])\n",
    "\t\ttrain_df['Temperature'] = temp_median_imputer.transform(train_df[['Temperature']])\n",
    "\t\ttest_df['Temperature'] = temp_median_imputer.transform(test_df[['Temperature']])\n",
    "\n",
    "\n",
    "\t# Drop columns\n",
    "\ttrain_df = train_df.drop(columns = ['Distance', 'ForecastId'])\n",
    "\ttest_df = test_df.drop(columns = ['Distance', 'ForecastId'])\n",
    "\n",
    "\ttrain_df['time_diff'] = train_df['Timestamp'].diff().fillna(0)\n",
    "\ttest_df['time_diff'] = test_df['Timestamp'].diff().fillna(0)\n",
    "\n",
    "\ttrain_df.head()\n",
    "\t\n",
    "\treturn train_df, test_df\n",
    "\n",
    "site_list = list(set(train['ForecastId']))\n",
    "\n",
    "processed_train = pd.DataFrame()\n",
    "processed_test = pd.DataFrame()\n",
    "\n",
    "for site in site_list:\n",
    "\ttrain_df, test_df = process(site)\n",
    "\tif processed_train.empty:\n",
    "\t\tprocessed_train = train_df\n",
    "\tprocessed_train = pd.concat([processed_train, train_df])\n",
    "\tif processed_test.empty:\n",
    "\t\tprocessed_test = test_df\n",
    "\tprocessed_test = pd.concat([processed_test, test_df])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
